<!DOCTYPE HTML>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-L56NNLSVLR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-L56NNLSVLR');
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiaxin Wen</title>

    <meta name="author" content="Jiaxin Wen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:top">
                <p class="name" style="text-align: center;">
                  Jiaxin Wen
                </p>
                <p>I'm a final-year Master's student at <a href='https://www.cs.tsinghua.edu.cn/'>Tsinghua University</a>. At Tsinghua, I'm working with <a href="http://coai.cs.tsinghua.edu.cn/hml/">Minlie Huang</a> and <a href="https://www.cs.tsinghua.edu.cn/csen/info/1313/4406.htm">Hongning Wang</a>. 
                  
                <p>I also work with researchers from UCB (<a href="https://ruiqi-zhong.github.io/">Ruiqi Zhong</a>), NYU (<a href="https://hhexiy.github.io/">He He</a>, <a href="https://ihsgnef.github.io/">Shi Feng</a>), and Anthropic (<a href="https://ethanperez.net/">Ethan Perez</a>, <a href="https://akbir.dev/about/">Akbir Khan</a>, <a href="https://jan.leike.name/">Jan Leike</a>).
                
                <!-- <p><span style="color: red; font-weight: bold;">I will graduate in 2025 and am seeking PhD or research scientist positions in superalignment.</span> Please reach out if you think I would be a good fit!</p> -->
                </p>
                <p style="text-align:center">
                  <a href="mailto:jiaxinwenthu@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV1117.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=jVRL96IAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Jiaxin-Wen">Github</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/jiaxinwen22">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/sakura.jpg"><img style="width:130%;max-width:130%" alt="profile photo" src="images/sakura.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research Overview</h2>
                <p>I want to build AI to tackle challenging tasks beyond human reach. Recently, I'm thinking about these questions:</p>
                <ul>
                  <li>
                    <a href="https://arxiv.org/pdf/2409.12822">What's the dangerous failure mode when building AI on these hard tasks?</a>
                  </li>
                  <li>
                  Which novel, high-value hard tasks (beyond math) can we use AI to address?
                  </li>
                  <li>
                  How can we build superhuman-level AI on these hard tasks via elicitation or generalization?
                  </li>
                  <li>
                  <a href="https://arxiv.org/pdf/2406.04604.pdf">How can we maintain humans' ability to understand, evaluate, and collaborate with AI on these hard tasks?</a>
                  </li>
                </ul>
                
                <p>These are all open questions, so I'm open to solve them through any possible ways.</p>
                <p>In particular, I think the fourth question is the hardest yet remains underinvested. I'd like to devote more time to it.</p>
                
                <p>
                  At my early career, I worked on improving <a href="https://arxiv.org/pdf/2211.16202.pdf">robustness</a>,  <a href="https://arxiv.org/pdf/2305.02606.pdf">long-context modeling</a> and <a href="https://arxiv.org/pdf/2409.12452">planning</a>. I also (co-)led the development of multiple pre-trained LMs (<a href="https://arxiv.org/pdf/2203.09313v1.pdf">EVA</a>, <a href="http://coai.cs.tsinghua.edu.cn/static/opd/posts/opd_blog">OPD</a>), and demos (<a href="data/final_thesis.pdf">Empathetic chatbot</a>, <a href="https://www.ai-topia.com/">Role-play chatbot</a>, and <a href="https://chatglm.cn/main/code">ChatGLM3 Code Interpreter</a>), which got millions of online queries.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Selected Papers</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            <tr>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Language Models Learn to Mislead Humans via RLHF</papertitle>
                </a>
                  <br>
                  <strong>Jiaxin Wen</strong>,
                  Ruiqi Zhong,
                  Akbir Khan,
                  Ethan Perez,
                  Jacob Steinhardt,
                  Minlie Huang,
                  Samuel R. Bowman,
                  He He,
                  Shi Feng
              <br>
                  <i>ICLR2025</i>
              <br>
                  <a href="https://arxiv.org/pdf/2409.12822">[paper]
              </td>
            </tr>
  

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning Task Decomposition to Assist Humans in Competitive Programming</papertitle>
              </a>
                <br>
                <strong>Jiaxin Wen</strong>,
                Ruiqi Zhong,
                Pei Ke,
                Zhihong Shao,
                Hongning Wang,
                Minlie Huang
            <br>
                <i>ACL 2024</i>
            <br>
                <a href="https://arxiv.org/pdf/2406.04604.pdf">[paper]
                <a href="data/assistv_poster.pdf">[poster]
                <!-- <a href="https://github.com/thu-coai/Implicit-Toxicity">[code]</a> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Unveiling the Implicit Toxicity in Large Language Models</papertitle>
              </a>
                <br>
                <strong>Jiaxin Wen</strong>,
                Pei Ke,
                Hao Sun,
                Zhexin Zhang,
                Changfei Li,
                Jinfeng Bai,
                Minlie Huang
            <br>
                <i>EMNLP 2023</i>
            <br>
                <a href="https://arxiv.org/pdf/2311.17391.pdf">[paper]</a>
                <a href="https://github.com/thu-coai/Implicit-Toxicity">[code]</a>
            </td>
          </tr>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Others</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Unlocking Reasoning Potential in Large Language Models by Scaling Code-form Planning</papertitle>
                </a>
                  <br>
                  <strong>Jiaxin Wen</strong><sup>*</sup>,
                  Jian Guan<sup>*</sup>,
                  Hongning Wang,
                  Wei Wu,
                  Minlie Huang
              <br>
                  <i>ICLR2025</i>
              <br>
                  <a href="https://arxiv.org/pdf/2409.12452">[paper]
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Adaptive Deployment of Untrusted LLMs Reduces Distributed Threats</papertitle>
                </a>
                  <br>
                  <strong>Jiaxin Wen*</strong>,
                  Vivek Hebbar*, Caleb Larson*, Aryan Bhatt, Ansh Radhakrishnan, Mrinank Sharma, Henry Sleight, Shi Feng, He He, Ethan Perez, Buck Shlegeris, Akbir Khan
              <br>
                  <i>ICLR2025</i>
              <br>
                  <a href="https://arxiv.org/pdf/2411.17693?">[paper]
                  <!-- <a href="https://github.com/thu-coai/Implicit-Toxicity">[code]</a> -->
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>AdaptiveBackdoor: Backdoored Language Model Agents that Detect Human Overseers</papertitle>
                </a>
                  <br>
                  Heng Wang,
                  Ruiqi Zhong,
                  <strong>Jiaxin Wen</strong>,
                  Jacob Steinhardt
              <br>
                  <i>ICML 2024 Next Generation of AI Safety Workshop</i>
              <br>
                  <a href="https://openreview.net/pdf?id=QdSJQAaoDp">[paper]
                  <!-- <a href="https://github.com/thu-coai/Implicit-Toxicity">[code]</a> -->
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>ETHICIST: Targeted Training Data Extraction Through Loss Smoothed Soft Prompting and Calibrated Confidence Estimation</papertitle>
              </a>
                <br>
                Zhexin Zhang,
                <strong>Jiaxin Wen</strong>,
                Minlie Huang
            <br>
                <i>ACL2023</i>
            <br>
                <a href="https://aclanthology.org/2023.acl-long.709.pdf">[paper]</a>
                <a href="https://github.com/thu-coai/Targeted-Data-Extraction">[code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Re3Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-training</papertitle>
              </a>
                <br>
                <strong>Jiaxin Wen</strong>,
                Hao Zhou,
                Jian Guan,
                Minlie Huang
            <br>
                <i>EMNLP 2023</i>
            <br>
                <a href="https://arxiv.org/pdf/2305.02606.pdf">[paper]</a>
                <a href="https://github.com/thu-coai/Re3Dial">[code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>AUGESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation</papertitle>
              </a>
                <br>
                Chujie Zheng, 
                Sahand Sabour, 
                <strong>Jiaxin Wen</strong>, 
                Zheng Zhang,
                Minlie Huang
            <br>
                <i>ACL2023 findings</i>
            <br>
                <a href="https://aclanthology.org/2023.findings-acl.99.pdf">[paper]</a>
                <a href="https://github.com/thu-coai/AugESC">[code]</a>
                <a href="https://huggingface.co/datasets/thu-coai/augesc">[dataset]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with Large-Scale Pre-Training</papertitle>
              </a>
                <br>
                Yuxian Gu<sup>*</sup>, 
                <strong>Jiaxin Wen</strong><sup>*</sup>, 
                Hao Sun<sup>*</sup>,
                Yi Song, Pei Ke, Chujie Zheng, Zheng Zhang, Jianzhu Yao, Xiaoyan Zhu, Jie Tang, Minlie Huang
            <br>
                <i>Machine Intelligence Research</i>
            <br>
              <a class="paperlink" href="https://arxiv.org/pdf/2203.09313v1.pdf">[paper] </a>
              <a class="paperlink" href="https://github.com/thu-coai/EVA">[code] </a>
              <a class="paperlink" href="data/eva_poster.pdf">[poster] </a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>AutoCAD: Automatically Generate Counterfactuals for Mitigating Shortcut Learning</papertitle>
              </a>
                <br>
                <strong>Jiaxin Wen</strong>, 
                Yeshuang Zhu,
                Jinchao Zhang,
                Jie Zhou,
                Minlie Huang
            <br>
                <i>EMNLP2022 findings</i>
            <br>
                <a href="https://arxiv.org/pdf/2211.16202.pdf">[paper]</a>
                <a href="https://github.com/thu-coai/AutoCAD">[code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Persona-Guided Planning for Controlling the Protagonistâ€™s Persona in Story Generation</papertitle>
              </a>
                <br>
                <strong>Jiaxin Wen</strong><sup>*</sup>, 
                Zhexin Zhang<sup>*</sup>,
                Jian Guan,
                Minlie Huang
            <br>
                <i>NAACL 2022</i>
            <br>
              <a class="paperlink" href="https://arxiv.org/pdf/2204.10703.pdf">[paper] </a>
              <a class="paperlink" href="https://github.com/thu-coai/ConPer">[code] </a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Robustness Testing of Language Understanding in Task-Oriented Dialog</papertitle>
              </a>
                <br>
                Jiexi Liu<sup>*</sup>,
                Ryuichi Takanobu<sup>*</sup>,
                <strong>Jiaxin Wen</strong>, 
                Dazhen Wan, Hongguang Li, Weiran Nie, Cheng Li, Wei Peng, Minlie Huang
            <br>
                <i>ACL 2021</i>
            <br>
              <a class="paperlink" href="https://aclanthology.org/2021.acl-long.192.pdf">[paper] </a>
              <a class="paperlink" href="https://github.com/thu-coai/ConvLab-2">[code] </a>
            </td>
          </tr>


          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Service</h2>
                </td>
              </tr>
          </tbody></table> -->
          <!-- <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td width="100%" valign="center">
                <li>2025: ICLR, COLM (Program Chair) </li>
                <li>2024: ACL, COLM, ICLR</li>
                <li>2023: EMNLP, ACL </li>
                <li>2022: EMNLP </li>
              </td>
            </tr>
          </tbody></table> -->

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Experiences</h2>
              </td>
            </tr>
          </tbody></table> -->
          <!-- <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td width="100%" valign="center">
                <li>June. 2024 - Present. Research Contractor, Anthropic, working with <a href="https://ethanperez.net/">Ethan Perez</a>, <a href="https://akbir.dev/about/">Akbir Khan</a>, and <a href="https://jan.leike.name/">Jan Leike</a></li>
                <li>June. 2024 - Present. Visiting Scholar, Alignment Research Group, working with <a href="https://hhexiy.github.io/">He He</a> and <a href="https://ihsgnef.github.io/">Shi Feng</a></li>
                <li>Mar. 2024 - Jun. 2024. Research Intern, LM Reasoning Team, Ant Research Group, working with <a href="https://sites.google.com/view/wei-wu-homepage/home">Wei Wu</a></li>
                <li>Jun. 2023 - Nov. 2023. Research Intern, Foundation Model Team, <a href="https://www.zhipuai.cn/">Zhipu AI</a>. </li>
              </td>
            </tr>
          </tbody></table> -->
        
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Honors & Awards</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td width="100%" valign="center">
                <li>Comprehensive Scholarship (Top-2), Tsinghua University &nbsp 2024 </li>
                <li>Research Excellence Scholarship, Tsinghua University &nbsp 2023 </li>
                <li>Outstanding Undergraduate Thesis (Top-5), Tsinghua University &nbsp 2022 </li>
                <li>Outstanding Graduate, Department of Computer Science and Technology, Tsinghua University &nbsp 2022 </li>
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellaneous</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td width="100%" valign="center">
                I have passions for a wide variety of fields, and I am constantly exploring new areas and possibilities. Some of my major interests include
                <ul>
                  <li><b>Sports:</b> I enjoy <s>body building</s> CrossFit recently. I'm aiming to run my first (half-)marathon this year, although it's been a month since my last 30KM running practice because it took me a week to recover :(. I'm also the member of Tsinghua hiking club and rugby team.</li>
                  <li><b>Literature:</b> I have always been a reader in literature. I served as the teaching assistant for the course "Writing and Communication" in 2021. My favorite authors are <a href="https://en.wikipedia.org/wiki/Hermann_Hesse">Hermann Karl Hesse</a>, <a href="https://en.wikipedia.org/wiki/Albert_Camus">Albert Camus</a>, and <a href="https://en.wikipedia.org/wiki/J._D._Salinger">Jerome David Salinger</a>.</li>
                </ul>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website design from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=3hXB2rS6NcHyG2tnFXZ36sY5mxNQkQYoy5DL5FWnJ7U'></script>
    </table>
    
  </body>
</html>
